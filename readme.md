# MACHINE LEARNING ACCELERATION

This repository contains experiments, models, and analysis related to **machine learning acceleration techniques**. The focus is on understanding how hardware-aware optimization, inference profiling, and model analysis can improve execution speed, power efficiency, and deployment viability of deep learning workloads.

## 📂 Repository Structure

.
├── Lab1/ # Introduction to inference benchmarking
├── Lab2/ # NVIDIA Nsight Compute + resnet18 profiling
├── Lab3/ # Systolic array simulations (e.g., with SCALE-Sim)
├── reports/ # PDF reports, analysis summaries
├── images/ # Supporting graphs and visualizations
└── README.md # Project overview

yaml
Copy
Edit

---

## 🚀 Highlights

- 📊 **Inference Analysis** using NVIDIA Nsight Compute
- 🧠 **CNN Model Profiling** (ResNet18) to understand memory & compute bottlenecks
- 🛠️ **Accelerator Simulation** using tools like SCALE-Sim
- 📁 Structured lab submissions and reports for reproducibility

---

## ⚙️ Tools & Technologies

- Python (NumPy, Matplotlib)
- Nsight Compute
- TensorFlow / PyTorch (for model exports)
- SCALE-Sim
- Git for version control

---

## 📎 File Sizes and Downloads

> 🔴 Note: Some large binary files (e.g., `.zip`, `.mov`, `.ncu-rep`) have been excluded from this repository due to GitHub’s file size limitations.  
> 👉 These files are available via [Google Drive link or Dropbox] — **please refer to the lab report PDFs for download instructions.**

---

## 🧠 Learning Outcomes

- Understand latency and throughput trade-offs in ML inference
- Gain hands-on exposure to hardware simulation tools
- Learn how architectural choices affect ML acceleration
- Develop intuition for DRAM bandwidth, array utilization, and on-chip memory tuning

---

## 📬 Contact

For any questions or collaborations, feel free to reach out:

**Mainak Malay Saha**  
📧 mainaksaha@asu.edu  
🌐 [mainaksaha.in](https://mainaksaha.in)

---

## 📜 License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.